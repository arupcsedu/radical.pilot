{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e927904a",
   "metadata": {},
   "source": [
    "<h1>3.8. Sharing Task Input Data</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cc07ac0",
   "metadata": {},
   "source": [
    "RP supports the concurrent execution of many tasks and, often, these tasks share some or all their input data, i.e., files. We have seen earlier that input staging can incur a significant runtime overhead. Such an overhead can be significantly reduced by avoiding redundant file staging operations.\n",
    "\n",
    "Each RP pilot manages a shared data space where to store tasksâ€™ input files. First, RP can stage input files into the shared data space of a pilot. Second, that pilot can create symbolic links (symlinks) in the work directory of each task to any file in the shared data space. In this way, set of tasks can access the same file, avoiding costly staging and replicating operations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d91992a9",
   "metadata": {},
   "source": [
    "Stage shared data from `pwd` to the pilot's shared data space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d983b401",
   "metadata": {},
   "outputs": [],
   "source": [
    "pilot.stage_in({'source': 'file://%s/input.dat' % os.getcwd(),\n",
    "                'target': 'staging:///input.dat',\n",
    "                'action': rp.TRANSFER})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c5f6400",
   "metadata": {},
   "source": [
    "Create a symlink in the work directory of each task to the file <i>input.dat</i>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a55fe874",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0, n):\n",
    "    cud = rp.TaskDescription()\n",
    "\n",
    "    cud.executable     = '/usr/bin/wc'\n",
    "    cud.arguments      = ['-c', 'input.dat']\n",
    "    cud.input_staging  = {'source': 'staging:///input.dat',\n",
    "                          'target': 'input.dat',\n",
    "                          'action': rp.LINK}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4b33a14",
   "metadata": {},
   "source": [
    "The rp.LINK staging action creates a symlink, avoiding the copy operation used by the rp.TRANSFER action.\n",
    "\n",
    "<b>Note:</b> Unlike other methods in RP, the pilot.stage_in method is synchronous, i.e., it only returns once the transfer is completed. This may change in a future version of RP."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a00e07e",
   "metadata": {},
   "source": [
    "<h2>3.8.1. Running the Example</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dcf7e67",
   "metadata": {},
   "source": [
    "The output of the below example is the same as <b>section 3.6</b>, but the script should run significantly faster due to the removed staging redundancy, especially for non-local pilots."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "545963d9",
   "metadata": {},
   "source": [
    "We start by importing the radical.pilot module and initializing the reporter facility used for printing well formatted runtime and progress information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35442353",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "verbose  = os.environ.get('RADICAL_PILOT_VERBOSE', 'REPORT')\n",
    "os.environ['RADICAL_PILOT_VERBOSE'] = verbose\n",
    "\n",
    "import radical.pilot as rp\n",
    "import radical.utils as ru\n",
    "\n",
    "report = ru.Reporter(name='radical.pilot')\n",
    "report.title('Getting Started (RP version %s)' % rp.version)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b98d5a2f",
   "metadata": {},
   "source": [
    "We will now import the dotenv module for fetching our environment variables. To create a new Session, you need to provide the URL of a MongoDB server which we will fetch from our .env file.\n",
    "\n",
    "We will set the resource value to 'local.localhost'. Using a resource key other than local.localhost implicitly tells RADICAL-Pilot that it is targeting a remote resource."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "330b6deb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "RADICAL_PILOT_DBURL = os.getenv(\"RADICAL_PILOT_DBURL\")\n",
    "os.environ['RADICAL_PILOT_DBURL'] = RADICAL_PILOT_DBURL\n",
    "resource = 'local.localhost'\n",
    "session = rp.Session()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "276c4a76",
   "metadata": {},
   "source": [
    "All other pilot code is now tried/excepted. If an exception is caught, we can rely on the session object to exist and be valid, and we can thus tear the whole RP stack down via a <i>'session.close()'</i> call in the '<i>finally'</i> clause."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a4de673",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "\n",
    "    # read the config used for resource details\n",
    "    report.info('read config')\n",
    "    config = ru.read_json('../config.json')\n",
    "    report.ok('>>ok\\n')\n",
    "\n",
    "    report.header('submit pilots')\n",
    "\n",
    "    # Add a Pilot Manager. Pilot managers manage one or more Pilots.\n",
    "    pmgr = rp.PilotManager(session=session)\n",
    "\n",
    "    # Define an [n]-core local pilot that runs for [x] minutes\n",
    "    # Here we use a dict to initialize the description object\n",
    "    pd_init = {\n",
    "               'resource'      : resource,\n",
    "               'runtime'       : 15,  # pilot runtime (min)\n",
    "               'exit_on_error' : True,\n",
    "               'project'       : config[resource].get('project', None),\n",
    "               'queue'         : config[resource].get('queue', None),\n",
    "               'access_schema' : config[resource].get('schema', None),\n",
    "               'cores'         : config[resource].get('cores', 1),\n",
    "               'gpus'          : config[resource].get('gpus', 0),\n",
    "              }\n",
    "    pdesc = rp.PilotDescription(pd_init)\n",
    "\n",
    "    # Launch the pilot.\n",
    "    pilot = pmgr.submit_pilots(pdesc)\n",
    "\n",
    "    # Create a workload of char-counting a simple file.  We first create the\n",
    "    # file right here, and stage it to the pilot 'shared_data' space\n",
    "    os.system('hostname >  input.dat')\n",
    "    os.system('date     >> input.dat')\n",
    "\n",
    "    # Synchronously stage the data to the pilot\n",
    "    report.info('stage in shared data')\n",
    "    pilot.stage_in({'source': 'client:///input.dat',\n",
    "                    'target': 'pilot:///input.dat',\n",
    "                    'action': rp.TRANSFER})\n",
    "    report.ok('>>ok\\n')\n",
    "\n",
    "\n",
    "    report.header('submit tasks')\n",
    "\n",
    "    # Register the Pilot in a TaskManager object.\n",
    "    tmgr = rp.TaskManager(session=session)\n",
    "    tmgr.add_pilots(pilot)\n",
    "\n",
    "    n = 128   # number of tasks to run\n",
    "    report.info('create %d task description(s)\\n\\t' % n)\n",
    "\n",
    "    tds = list()\n",
    "    outs = list()\n",
    "    for i in range(0, n):\n",
    "\n",
    "        # create a new Task description, and fill it.\n",
    "        # Here we don't use dict initialization.\n",
    "        td = rp.TaskDescription()\n",
    "        td.executable     = '/bin/cat'\n",
    "        td.arguments      = ['input.dat']\n",
    "        td.stdout         = 'STDOUT'\n",
    "        td.input_staging  = {'source': 'pilot:///input.dat',\n",
    "                             'target': 'task:///input.dat',\n",
    "                             'action': rp.LINK}\n",
    "        td.output_staging = {'source': 'task:///STDOUT',\n",
    "                             'target': 'pilot:///STDOUT.%06d' % i,\n",
    "                             'action': rp.COPY}\n",
    "        outs.append('STDOUT.%06d' % i)\n",
    "        tds.append(td)\n",
    "        report.progress()\n",
    "    report.ok('>>ok\\n')\n",
    "\n",
    "    # Submit the previously created Task descriptions to the\n",
    "    # PilotManager. This will trigger the selected scheduler to start\n",
    "    # assigning Tasks to the Pilots.\n",
    "    tasks = tmgr.submit_tasks(tds)\n",
    "\n",
    "    # Wait for all tasks to reach a final state (DONE, CANCELED or FAILED).\n",
    "    report.header('gather results')\n",
    "    tmgr.wait_tasks()\n",
    "\n",
    "    report.info('\\n')\n",
    "    for task in tasks:\n",
    "        report.plain('  * %s: %s, exit: %3s, out: %s\\n'\n",
    "                % (task.uid, task.state[:4],\n",
    "                    task.exit_code, task.stdout.strip()[:35]))\n",
    "\n",
    "    # delete the sample input files\n",
    "    os.system('rm input.dat')\n",
    "\n",
    "    # Synchronously stage the data to the pilot\n",
    "    report.info('stage out shared data')\n",
    "    pilot.stage_out([{'source': 'pilot:///%s'  % fname,\n",
    "                      'target': 'client:///%s' % fname,\n",
    "                      'action': rp.TRANSFER} for fname in outs])\n",
    "    report.ok('>>ok\\n')\n",
    "\n",
    "\n",
    "finally:\n",
    "    # always clean up the session, no matter if we caught an exception or\n",
    "    # not.  This will kill all remaining pilots.\n",
    "    report.header('finalize')\n",
    "    session.close()\n",
    "\n",
    "report.header()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
