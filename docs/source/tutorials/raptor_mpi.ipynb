{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a2f88f94-378f-4bde-bdeb-2f4ce810c908",
   "metadata": {},
   "source": [
    "# Executing MPI Tasks with RAPTOR\n",
    "\n",
    "This notebook will walk you through setting up and using the RAPTOR subsystem to execute **MPI function** tasks. To execute MPI functions with RAPTOR, we need to specify the type and size of the worker to be deployed by RAPTOR. The primary purpose of using RAPTOR to execute MPI functions is RAPTOR's capabilities to construct and deliver heterogeneous (different ranks) private MPI communicators during the execution time to the function. In the example below, we will execute an MPI function that requires 4 MPI ranks, and for that, we will deploy a single master and worker.\n",
    "\n",
    "<div class=\"alert alert-warning\">\n",
    "\n",
    "__Warning:__ We assume you have already worked through our [raptor](../raptor.ipynb) tutorial.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed034a4d-bf9b-432a-94bb-2f4e471c39bc",
   "metadata": {},
   "source": [
    "## Prepare a RP pilot to host RAPTOR\n",
    "We will launch a pilot with sufficient resources to run both the raptor master (using 1 core) and a single worker instances (using 10 cores):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1c1aa520-67ac-4322-b89e-678d1e48d64e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[94mnew session: \u001b[39m\u001b[0m[rp.session.surfacebook.aymen.019634.0001]\u001b[39m\u001b[0m\u001b[94m                        \\\n",
      "zmq proxy  : \u001b[39m\u001b[0m[tcp://172.23.228.232:10001]\u001b[39m\u001b[0m\u001b[92m                                     ok\n",
      "\u001b[39m\u001b[0m\u001b[94mcreate pilot manager\u001b[39m\u001b[0m\u001b[92m                                                          ok\n",
      "\u001b[39m\u001b[0m\u001b[94mcreate task manager\u001b[39m\u001b[0m\u001b[92m                                                           ok\n",
      "\u001b[39m\u001b[0m\u001b[94msubmit 1 pilot(s)\u001b[39m\u001b[0m\n",
      "        pilot.0000   local.localhost          17 cores       0 gpus\u001b[39m\u001b[0m\u001b[92m           ok\n",
      "\u001b[39m\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pilot is up and running\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# do not use animated output in notebooks\n",
    "os.environ['RADICAL_REPORT_ANIME'] = 'False'\n",
    "\n",
    "import radical.pilot as rp\n",
    "import radical.utils as ru\n",
    "\n",
    "# determine the path of the currently active ve to simplify some examples below\n",
    "ve_path = os.path.dirname(os.path.dirname(ru.which('python3')))\n",
    "\n",
    "# create session and managers\n",
    "session = rp.Session()\n",
    "pmgr    = rp.PilotManager(session)\n",
    "tmgr    = rp.TaskManager(session)\n",
    "\n",
    "# submit a pilot\n",
    "pilot = pmgr.submit_pilots(rp.PilotDescription({'resource'     : 'local.localhost', \n",
    "                                                'runtime'      : 60, \n",
    "                                                'cores'        : 17, \n",
    "                                                'exit_on_error': False}))\n",
    "\n",
    "# add the pilot to the task manager and wait for the pilot to become active\n",
    "tmgr.add_pilots(pilot)\n",
    "pilot.wait(rp.PMGR_ACTIVE)\n",
    "print('pilot is up and running')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f1b35ed-4cac-4a0e-b530-ad71c3a4850a",
   "metadata": {},
   "source": [
    "The pilot is now in an `ACTIVE` state, and the resource is acquired."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30306b21-0bdb-49d2-8280-52e91bfe351e",
   "metadata": {},
   "source": [
    "Define a Python function that requires running in an MPI environment and use the `rp.pythontask` decorator so the function can be serialized by RP. Note that this function takes a `comm` argument, representing the MPI communicator that this function needs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7ea76f13-6770-4ae0-a0e4-d6b49cc17120",
   "metadata": {},
   "outputs": [],
   "source": [
    "@rp.pythontask\n",
    "def func_mpi(comm, msg, sleep=2):\n",
    "    import time\n",
    "    print('hello %d/%d: %s' % (comm.rank, comm.size, msg))\n",
    "    time.sleep(sleep)\n",
    "    return 'func_mpi retval'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e954c4e-e3fe-4a59-ba75-c6df3c1d05c1",
   "metadata": {},
   "source": [
    "Create a master and MPI worker by specifiying the `raptor_class: MPIWorker` in the worker description below. This value will instruct RAPTOR to start the MPI worker rather than the `DefaultWorker`. Note that we also specified the number of `ranks` (cores) in the worker description to a number **larger** than the required number of ranks for the designated MPI task function in order for the function to be executed on that worker.\n",
    "\n",
    "<div class=\"alert alert-warning\">\n",
    "\n",
    "__Warning:__ The number of master(s) and worker(s) depends on the workload specifications and the use case that you are trying to execute. Sometimes, you might be required to deploy two masters and workers instead of 1 for more efficient load balancing. \n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "496c9e29-830d-4ccd-be55-4808c0a54511",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "submit: \u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m\n",
      "\u001b[39m\u001b[0msubmit: \u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m\n",
      "\u001b[39m\u001b[0m"
     ]
    }
   ],
   "source": [
    "master_descr = {'mode': rp.RAPTOR_MASTER,\n",
    "                'named_env': 'rp'}\n",
    "worker_descr = {'mode': rp.RAPTOR_WORKER,\n",
    "                'named_env': 'rp',\n",
    "                'ranks': 10,\n",
    "                'raptor_class': 'MPIWorker'}\n",
    "\n",
    "raptor = pilot.submit_raptors( [rp.TaskDescription(master_descr)])[0]\n",
    "worker = raptor.submit_workers([rp.TaskDescription(worker_descr), \n",
    "                                rp.TaskDescription(worker_descr)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "252c0b5a-b71f-4217-b162-900b4c3021b7",
   "metadata": {},
   "source": [
    "Create a `rp.TaskDescription` and specify the function object and the number of `ranks` required to run the function within (the number of ranks also represents the size of the `comm` object passed to the function during the execution time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2981e8d6-8c35-49e7-b205-53eb51d798b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "submit: \u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m\n",
      "\u001b[39m\u001b[0m"
     ]
    }
   ],
   "source": [
    "# create a minimal MPI function task\n",
    "td = rp.TaskDescription({'mode': rp.TASK_FUNCTION,\n",
    "                         'ranks': 4,\n",
    "                         'function': func_mpi(None, msg='mpi_task.0')})\n",
    "mpi_task = raptor.submit_tasks([td])[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c99d190a-b214-4a2a-98da-a0b8b2f0ac8e",
   "metadata": {},
   "source": [
    "Wait for the task status to be reported back."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a9e67c02-96ec-4b08-a620-3f186e7e9522",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wait  : \u001b[39m\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['task.000000', '', 'AGENT_STAGING_INPUT_PENDING']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m\n",
      "\u001b[39m\u001b[0m\u001b[94m\tDONE      :     1\n",
      "\u001b[39m\u001b[0m\u001b[92m                                                                              ok\n",
      "\u001b[39m\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id: task.000000 [DONE]:\n",
      "    out:\n",
      "['hello 0/4: mpi_task.0\\n', 'hello 1/4: mpi_task.0\\n', 'hello 2/4: mpi_task.0\\n', 'hello 3/4: mpi_task.0\\n']\n",
      "    ret: ['func_mpi retval', 'func_mpi retval', 'func_mpi retval', 'func_mpi retval']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(mpi_task)\n",
    "tmgr.wait_tasks([mpi_task.uid])\n",
    "print('id: %s [%s]:\\n    out:\\n%s\\n    ret: %s\\n'\n",
    "     % (mpi_task.uid, mpi_task.state, mpi_task.stdout, mpi_task.return_value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7419ade7-3bf1-4ab2-8ab1-a671fe3746b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[94mclosing session rp.session.surfacebook.aymen.019634.0001\u001b[39m\u001b[0m\u001b[94m                       \\\n",
      "close task manager\u001b[39m\u001b[0m\u001b[92m                                                            ok\n",
      "\u001b[39m\u001b[0m\u001b[94mclose pilot manager\u001b[39m\u001b[0m\u001b[94m                                                            \\\n",
      "wait for 1 pilot(s)\n",
      "        \u001b[39m\u001b[0m\u001b[92m                                                                      ok\n",
      "\u001b[39m\u001b[0m\u001b[92m                                                                              ok\n",
      "\u001b[39m\u001b[0m\u001b[94msession lifetime: 55.6s\u001b[39m\u001b[0m\u001b[92m                                                       ok\n",
      "\u001b[39m\u001b[0m"
     ]
    }
   ],
   "source": [
    "session.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
