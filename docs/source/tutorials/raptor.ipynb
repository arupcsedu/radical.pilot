{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "67521807",
   "metadata": {},
   "source": [
    "# Executing Tasks with RAPTOR\n",
    "\n",
    "This notebook introduces you to RAPTOR, a high-throughput RADICAL-Pilot's subsystem that executes **function** tasks and non-MPI executable tasks at scale on [supported HPC platforms](../supported.rst). This tutorial will guide you through the setup and configuration of RAPTOR and through the specification and execution of a variety of task types.\n",
    "\n",
    "<div class=\"alert alert-warning\">\n",
    "\n",
    "__Warning:__ We assume you have already worked through our [getting started](../getting_started.ipynb) and [describing tasks](describing_tasks.ipynb) tutorials.\n",
    "\n",
    "</div>\n",
    "\n",
    "<div class=\"alert alert-warning\">\n",
    "\n",
    "__Warning:__ All examples in this notebook are executed locally on your machine.  You need to have installed MPI before executing these examples. RADICAL-Pilot and RAPTOR support OpenMPI, MPICH, MVAPICH or any other MPI flavor that provides a standards compliant `mpiexec` command.\n",
    "\n",
    "</div>\n",
    "\n",
    "## When Using RAPTOR\n",
    "\n",
    "Use RAPTOR when you want to concurrently execute free/serialized Python functions, Python class methods and shell commands. For example, you want to concurrently execute up to 10^5 machine learning functions across thousands of GPUs and CPUs. RAPTOR supports single, multi-process and MPI Python functions.\n",
    "\n",
    "You should also use RAPTOR when your application requires non-MPI tasks which execute for less than 5 minutes. You could use RADICAL-Pilot without RAPTOR for that workload but you would incur into high scheduling and launching overheads.\n",
    "\n",
    "## What is RAPTOR\n",
    "\n",
    "RAPTOR is a subsystem of RP, thus you have to execute RP in order to use RAPTOR.  RAPTOR launches a configurable number of masters and workers on the resources you acquired via RP. Once up and running, each RAPTOR's master\n",
    "will receive task execution requests from RP. In turn, each master will dispatch those requests to the workers which are optimized to execute small, short-running tasks at scale.\n",
    "\n",
    "Different from RP's 'normal' task, RAPTOR can execute a variety of task types:\n",
    "\n",
    "- executables: similar to RP's native task execution, but without MPI support\n",
    "- free Python functions\n",
    "- Python class methods\n",
    "- serialized Python functions\n",
    "- plain Python code\n",
    "- shell commands\n",
    "\n",
    "Importantly, all function invocations can make use of MPI by defining multiple ranks.  \n",
    "\n",
    "RAPTOR has a number of advanced capabilities, such as:\n",
    "\n",
    "- new task types can be added by applications\n",
    "- the RAPTOR Master class can be overloaded by applications\n",
    "- the RAPTOR Worker class can be overloaded by applications\n",
    "- Master and Worker layout can be tuned in a variety of ways\n",
    "- different Worker implementations are available with different capabilities and scaling properties\n",
    "- workload execution can mix RAPTOR task execution and 'normal' RP task execution\n",
    "  \n",
    "Those topics will not be covered in this basic tutorial.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5958a7c2",
   "metadata": {},
   "source": [
    "\n",
    "## Prepare a RP pilot to host RAPTOR\n",
    "\n",
    "We will launch a pilot with sufficient resources to run both the raptor master (using 1 core) and two worker instances (using 8 cores each):\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c8b8387d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[94mnew session: \u001b[39m\u001b[0m[rp.session.surfacebook.aymen.019628.0007]\u001b[39m\u001b[0m\u001b[94m                        \\\n",
      "database   : \u001b[39m\u001b[0m[mongodb://aymen:****@95.217.193.116:27017/radical3]\u001b[39m\u001b[0m\u001b[92m             ok\n",
      "\u001b[39m\u001b[0m\u001b[94mcreate pilot manager\u001b[39m\u001b[0m\u001b[92m                                                          ok\n",
      "\u001b[39m\u001b[0m\u001b[94mcreate task manager\u001b[39m\u001b[0m\u001b[92m                                                           ok\n",
      "\u001b[39m\u001b[0m\u001b[94msubmit 1 pilot(s)\u001b[39m\u001b[0m\n",
      "        pilot.0000   local.localhost          17 cores       0 gpus\u001b[39m\u001b[0m\u001b[92m           ok\n",
      "\u001b[39m\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pilot is up and running\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# do not use animated output in notebooks\n",
    "os.environ['RADICAL_REPORT_ANIME'] = 'False'\n",
    "\n",
    "import radical.pilot as rp\n",
    "import radical.utils as ru\n",
    "\n",
    "# determine the path of the currently active ve to simplify some examples below\n",
    "ve_path = os.path.dirname(os.path.dirname(ru.which('python3')))\n",
    "\n",
    "# create session and managers\n",
    "session = rp.Session()\n",
    "pmgr    = rp.PilotManager(session)\n",
    "tmgr    = rp.TaskManager(session)\n",
    "\n",
    "# submit a pilot\n",
    "pilot = pmgr.submit_pilots(rp.PilotDescription({'resource'     : 'local.localhost', \n",
    "                                                'runtime'      : 60, \n",
    "                                                'cores'        : 17, \n",
    "                                                'exit_on_error': False}))\n",
    "\n",
    "# add the pilot to the task manager and wait for the pilot to become active\n",
    "tmgr.add_pilots(pilot)\n",
    "pilot.wait(rp.PMGR_ACTIVE)\n",
    "print('pilot is up and running')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50b5bb36",
   "metadata": {},
   "source": [
    "\n",
    "We now have an active pilot with sufficient resource and can start executing the RAPTOR master and worker instances.  Both master and woprker need to run in an environment which has `radical.pilot` installed, so we place it in the pilot agent environment `rp` (the `named_env` attribute is covered by the tutorial [describing tasks](describing_tasks.ipynb)):\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b1c41c91",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "submit: \u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m\n",
      "\u001b[39m\u001b[0msubmit: \u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m\n",
      "\u001b[39m\u001b[0m"
     ]
    }
   ],
   "source": [
    "master_descr = {'mode'     : rp.RAPTOR_MASTER,\n",
    "                'named_env': 'rp'}\n",
    "worker_descr = {'mode'     : rp.RAPTOR_WORKER,\n",
    "                'named_env': 'rp'}\n",
    "\n",
    "raptor  = pilot.submit_raptors( [rp.TaskDescription(master_descr)])[0]\n",
    "workers = raptor.submit_workers([rp.TaskDescription(worker_descr), \n",
    "                                 rp.TaskDescription(worker_descr)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ce411cb",
   "metadata": {},
   "source": [
    "### Task execution\n",
    "\n",
    "At this point we have the pilot set up and running, we started the master task, and the master will upon initialization start the worker tasks: the RAPTOR overlay is now ready to execute a Python function.  The default RAPTOR Worker has a built-in test function which you can use for testing purpose:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "71eb4ff2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "submit: \u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m\n",
      "\u001b[39m\u001b[0m"
     ]
    }
   ],
   "source": [
    "# create a minimal function task\n",
    "td   = rp.TaskDescription({'mode'     : rp.TASK_FUNCTION,\n",
    "                           'function' : 'test', \n",
    "                           'args'     : [1, 2]})\n",
    "task = raptor.submit_tasks([td])[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03112275",
   "metadata": {},
   "source": [
    "The task will be scheduled for execution on the pilot we created above.  We now wait for the task to complete, i.e., to reach one of the final states `DONE`, `CANCELED` or `FAILED`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5f2ea29b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wait  : \u001b[39m\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['task.000000', 'pilot.0000', 'AGENT_STAGING_INPUT_PENDING']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m\n",
      "\u001b[39m\u001b[0m\u001b[94m\tDONE      :     1\n",
      "\u001b[39m\u001b[0m\u001b[92m                                                                              ok\n",
      "\u001b[39m\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id: task.000000 [DONE]:\n",
      "    out:\n",
      "start idx 1: 1695928381.0\n",
      "stop  idx 1: 1695928383.0\n",
      "\n",
      "    ret: None\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(task)\n",
    "tmgr.wait_tasks([task.uid])\n",
    "print('id: %s [%s]:\\n    out:\\n%s\\n    ret: %s\\n'\n",
    "     % (task.uid, task.state, task.stdout, task.return_value))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdf95506",
   "metadata": {},
   "source": [
    "### MPI Task execution\n",
    "\n",
    "To execute MPI functions with RAPTOR, we need to specify the type and size of the worker to be deployed by RAPTOR. The primary purpose of using RAPTOR to execute MPI functions is the capabilities of RAPTOR to construct and deliver heterogeneous (different ranks) private MPI communicators during the execution time to the function. In the example below, we will execute an MPI function that requires 4 MPI ranks, and for that, we will deploy a single master and worker.\n",
    "\n",
    "<div class=\"alert alert-warning\">\n",
    "\n",
    "__Warning:__ The number of master(s) and worker(s) depends on the workload specifications and the use case that you are trying to execute. Sometimes, you might be required to deploy two masters and workers instead of 1 for more efficient load balancing. \n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3518624",
   "metadata": {},
   "source": [
    "Define a Python function that requires running in an MPI environment and use the `rp.pythontask` decorator so the function can be serialized by RP. Note that this function takes a `comm` argument, representing the MPI communicator that this function needs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5ab54591",
   "metadata": {},
   "outputs": [],
   "source": [
    "@rp.pythontask\n",
    "def func_mpi(comm, msg, sleep=2):\n",
    "    import time\n",
    "    print('hello %d/%d: %s' % (comm.rank, comm.size, msg))\n",
    "    time.sleep(sleep)\n",
    "    return 'func_mpi retval'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b67bb8dc",
   "metadata": {},
   "source": [
    "Create a master and MPI worker by specifiying the `raptor_class: MPIWorker` in the worker description below. This value will instruct RAPTOR to start the MPI worker rather than the `DefaultWorker`. Note that we also specified the number of `ranks` (cores) in the worker description to a number **larger** than the required number of ranks for the designated MPI task function in order for the function to be executed on that worker."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "97b210d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "submit: \u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m\n",
      "\u001b[39m\u001b[0msubmit: \u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m\n",
      "\u001b[39m\u001b[0m"
     ]
    }
   ],
   "source": [
    "master_descr = {'mode': rp.RAPTOR_MASTER,\n",
    "                'named_env': 'rp'}\n",
    "worker_descr = {'mode': rp.RAPTOR_WORKER,\n",
    "                'named_env': 'rp',\n",
    "                'ranks': 10,\n",
    "                'raptor_class': 'MPIWorker'}\n",
    "\n",
    "raptor = pilot.submit_raptors( [rp.TaskDescription(master_descr)])[0]\n",
    "worker = raptor.submit_workers([rp.TaskDescription(worker_descr), \n",
    "                                rp.TaskDescription(worker_descr)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a1e7294",
   "metadata": {},
   "source": [
    "Create a `rp.TaskDescription` and specify the function object and the number of `ranks` required to run the function within (the number of ranks also represents the size of the `comm` object passed to the function during the execution time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ecd67094",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "submit: \u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m\n",
      "\u001b[39m\u001b[0m"
     ]
    }
   ],
   "source": [
    "# create a minimal MPI function task\n",
    "td = rp.TaskDescription({'mode': rp.TASK_FUNCTION,\n",
    "                         'ranks': 4,\n",
    "                         'function': func_mpi(None, msg='mpi_task.0')})\n",
    "mpi_task = raptor.submit_tasks([td])[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5322563",
   "metadata": {},
   "source": [
    "Wait for the task status to be reported back."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1d3966d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wait  : \u001b[39m\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['task.000001', 'pilot.0000', 'AGENT_SCHEDULING']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m#\u001b[39m\u001b[0m\n",
      "\u001b[39m\u001b[0m\u001b[94m\tDONE      :     1\n",
      "\u001b[39m\u001b[0m\u001b[92m                                                                              ok\n",
      "\u001b[39m\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id: task.000001 [DONE]:\n",
      "    out:\n",
      "['hello 3/4: mpi_task.0\\n', 'hello 1/4: mpi_task.0\\n', 'hello 0/4: mpi_task.0\\n', 'hello 2/4: mpi_task.0\\n']\n",
      "    ret: ['func_mpi retval', 'func_mpi retval', 'func_mpi retval', 'func_mpi retval']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(mpi_task)\n",
    "tmgr.wait_tasks([mpi_task.uid])\n",
    "print('id: %s [%s]:\\n    out:\\n%s\\n    ret: %s\\n'\n",
    "     % (mpi_task.uid, mpi_task.state, mpi_task.stdout, mpi_task.return_value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fdd9fe6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[94mclosing session rp.session.surfacebook.aymen.019628.0007\u001b[39m\u001b[0m\u001b[94m                       \\\n",
      "close task manager\u001b[39m\u001b[0m\u001b[92m                                                            ok\n",
      "\u001b[39m\u001b[0m\u001b[94mclose pilot manager\u001b[39m\u001b[0m\u001b[94m                                                            \\\n",
      "wait for 1 pilot(s)\n",
      "        \u001b[39m\u001b[0m"
     ]
    }
   ],
   "source": [
    "session.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86674d93-f890-48b8-b7c1-cf765860fee8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
